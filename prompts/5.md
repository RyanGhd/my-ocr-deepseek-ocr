I have the following code

```
#deepseek OCR
from transformers import AutoModel, AutoTokenizer
import torch
import os
os.environ["CUDA_VISIBLE_DEVICES"] = '0'
model_name = 'deepseek-ai/DeepSeek-OCR'

tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
model = AutoModel.from_pretrained(model_name, _attn_implementation='flash_attention_2', trust_remote_code=True, use_safetensors=True)
model = model.eval().cuda().to(torch.bfloat16)

# prompt = "<image>\nFree OCR. "
prompt = "<image>\n<|grounding|>Convert the document to markdown. "
image_file = 'images/1.png'
output_path = 'images_output'

# infer(self, tokenizer, prompt='', image_file='', output_path = ' ', base_size = 1024, image_size = 640, crop_mode = True, test_compress = False, save_results = False):

# Tiny: base_size = 512, image_size = 512, crop_mode = False
# Small: base_size = 640, image_size = 640, crop_mode = False
# Base: base_size = 1024, image_size = 1024, crop_mode = False
# Large: base_size = 1280, image_size = 1280, crop_mode = False

# Gundam: base_size = 1024, image_size = 640, crop_mode = True

res = model.infer(tokenizer, prompt=prompt, image_file=image_file, output_path = output_path, base_size = 1024, image_size = 640, crop_mode=True, save_results = True, test_compress = True)
```

I run this in a jupyter notebook in vertex ai notebook instance

The instance is private and doesn't have access to the internet 

it throws the following error:
```
'(MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /deepseek-ai/DeepSeek-OCR/resolve/main/tokenizer_config.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x798806880dc0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: bf30b1f9-0c66-4854-8736-90359c89cc67)')' thrown while requesting HEAD https://huggingface.co/deepseek-ai/DeepSeek-OCR/resolve/main/tokenizer_config.json
Retrying in 1s [Retry 1/5].
'(MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /deepseek-ai/DeepSeek-OCR/resolve/main/tokenizer_config.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x798806880fa0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: f0278d44-b7da-4857-846c-5d6746a1b9d8)')' thrown while requesting HEAD https://huggingface.co/deepseek-ai/DeepSeek-OCR/resolve/main/tokenizer_config.json
Retrying in 2s [Retry 2/5].
---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
Cell In[7], line 8
      5 os.environ["CUDA_VISIBLE_DEVICES"] = '0'
      6 model_name = 'deepseek-ai/DeepSeek-OCR'
----> 8 tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
      9 model = AutoModel.from_pretrained(model_name, _attn_implementation='flash_attention_2', trust_remote_code=True, use_safetensors=True)
     10 model = model.eval().cuda().to(torch.bfloat16)

File /opt/micromamba/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:857, in AutoTokenizer.from_pretrained(cls, pretrained_model_name_or_path, *inputs, **kwargs)
    854     return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
    856 # Next, let's try to use the tokenizer_config file to get the tokenizer class.
--> 857 tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
    858 if "_commit_hash" in tokenizer_config:
    859     kwargs["_commit_hash"] = tokenizer_config["_commit_hash"]

File /opt/micromamba/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:689, in get_tokenizer_config(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)
    686     token = use_auth_token
    688 commit_hash = kwargs.get("_commit_hash", None)
--> 689 resolved_config_file = cached_file(
    690     pretrained_model_name_or_path,
    691     TOKENIZER_CONFIG_FILE,
    692     cache_dir=cache_dir,
    693     force_download=force_download,
    694     resume_download=resume_download,
    695     proxies=proxies,
    696     token=token,
    697     revision=revision,
    698     local_files_only=local_files_only,
    699     subfolder=subfolder,
    700     _raise_exceptions_for_gated_repo=False,
    701     _raise_exceptions_for_missing_entries=False,
    702     _raise_exceptions_for_connection_errors=False,
    703     _commit_hash=commit_hash,
    704 )
    705 if resolved_config_file is None:
    706     logger.info("Could not locate the tokenizer configuration file, will try to use the model config instead.")

File /opt/micromamba/lib/python3.10/site-packages/transformers/utils/hub.py:403, in cached_file(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)
    400 user_agent = http_user_agent(user_agent)
    401 try:
    402     # Load from URL or cache if already cached
--> 403     resolved_file = hf_hub_download(
    404         path_or_repo_id,
    405         filename,
    406         subfolder=None if len(subfolder) == 0 else subfolder,
    407         repo_type=repo_type,
    408         revision=revision,
    409         cache_dir=cache_dir,
    410         user_agent=user_agent,
    411         force_download=force_download,
    412         proxies=proxies,
    413         resume_download=resume_download,
    414         token=token,
    415         local_files_only=local_files_only,
    416     )
    417 except GatedRepoError as e:
    418     resolved_file = _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)

File /opt/micromamba/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114, in validate_hf_hub_args.<locals>._inner_fn(*args, **kwargs)
    111 if check_use_auth_token:
    112     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.__name__, has_token=has_token, kwargs=kwargs)
--> 114 return fn(*args, **kwargs)

File /opt/micromamba/lib/python3.10/site-packages/huggingface_hub/file_download.py:1007, in hf_hub_download(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)
    987     return _hf_hub_download_to_local_dir(
    988         # Destination
    989         local_dir=local_dir,
   (...)
   1004         local_files_only=local_files_only,
   1005     )
   1006 else:
-> 1007     return _hf_hub_download_to_cache_dir(
   1008         # Destination
   1009         cache_dir=cache_dir,
   1010         # File info
   1011         repo_id=repo_id,
   1012         filename=filename,
   1013         repo_type=repo_type,
   1014         revision=revision,
   1015         # HTTP info
   1016         endpoint=endpoint,
   1017         etag_timeout=etag_timeout,
   1018         headers=hf_headers,
   1019         proxies=proxies,
   1020         token=token,
   1021         # Additional options
   1022         local_files_only=local_files_only,
   1023         force_download=force_download,
   1024     )

File /opt/micromamba/lib/python3.10/site-packages/huggingface_hub/file_download.py:1070, in _hf_hub_download_to_cache_dir(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)
   1066         return pointer_path
   1068 # Try to get metadata (etag, commit_hash, url, size) from the server.
   1069 # If we can't, a HEAD request error is returned.
-> 1070 (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) = _get_metadata_or_catch_error(
   1071     repo_id=repo_id,
   1072     filename=filename,
   1073     repo_type=repo_type,
   1074     revision=revision,
   1075     endpoint=endpoint,
   1076     proxies=proxies,
   1077     etag_timeout=etag_timeout,
   1078     headers=headers,
   1079     token=token,
   1080     local_files_only=local_files_only,
   1081     storage_folder=storage_folder,
   1082     relative_filename=relative_filename,
   1083 )
   1085 # etag can be None for several reasons:
   1086 # 1. we passed local_files_only.
   1087 # 2. we don't have a connection
   (...)
   1093 # If the specified revision is a commit hash, look inside "snapshots".
   1094 # If the specified revision is a branch or tag, look inside "refs".
   1095 if head_call_error is not None:
   1096     # Couldn't make a HEAD call => let's try to find a local file

File /opt/micromamba/lib/python3.10/site-packages/huggingface_hub/file_download.py:1543, in _get_metadata_or_catch_error(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)
   1541 try:
   1542     try:
-> 1543         metadata = get_hf_file_metadata(
   1544             url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
   1545         )
   1546     except EntryNotFoundError as http_error:
   1547         if storage_folder is not None and relative_filename is not None:
   1548             # Cache the non-existence of the file

File /opt/micromamba/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114, in validate_hf_hub_args.<locals>._inner_fn(*args, **kwargs)
    111 if check_use_auth_token:
    112     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.__name__, has_token=has_token, kwargs=kwargs)
--> 114 return fn(*args, **kwargs)

File /opt/micromamba/lib/python3.10/site-packages/huggingface_hub/file_download.py:1460, in get_hf_file_metadata(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)
   1457 hf_headers["Accept-Encoding"] = "identity"  # prevent any compression => we want to know the real size of the file
   1459 # Retrieve metadata
-> 1460 r = _request_wrapper(
   1461     method="HEAD",
   1462     url=url,
   1463     headers=hf_headers,
   1464     allow_redirects=False,
   1465     follow_relative_redirects=True,
   1466     proxies=proxies,
   1467     timeout=timeout,
   1468 )
   1469 hf_raise_for_status(r)
   1471 # Return

File /opt/micromamba/lib/python3.10/site-packages/huggingface_hub/file_download.py:283, in _request_wrapper(method, url, follow_relative_redirects, **params)
    281 # Recursively follow relative redirects
    282 if follow_relative_redirects:
--> 283     response = _request_wrapper(
    284         method=method,
    285         url=url,
    286         follow_relative_redirects=False,
    287         **params,
    288     )
    290     # If redirection, we redirect only relative paths.
    291     # This is useful in case of a renamed repository.
    292     if 300 <= response.status_code <= 399:

File /opt/micromamba/lib/python3.10/site-packages/huggingface_hub/file_download.py:306, in _request_wrapper(method, url, follow_relative_redirects, **params)
    303     return response
    305 # Perform request and return if status_code is not in the retry list.
--> 306 response = http_backoff(method=method, url=url, **params)
    307 hf_raise_for_status(response)
    308 return response

File /opt/micromamba/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:306, in http_backoff(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)
    303     kwargs["data"].seek(io_obj_initial_pos)
    305 # Perform request and return if status_code is not in the retry list.
--> 306 response = session.request(method=method, url=url, **kwargs)
    307 if response.status_code not in retry_on_status_codes:
    308     return response

File /opt/micromamba/lib/python3.10/site-packages/requests/sessions.py:589, in Session.request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)
    584 send_kwargs = {
    585     "timeout": timeout,
    586     "allow_redirects": allow_redirects,
    587 }
    588 send_kwargs.update(settings)
--> 589 resp = self.send(prep, **send_kwargs)
    591 return resp

File /opt/micromamba/lib/python3.10/site-packages/requests/sessions.py:703, in Session.send(self, request, **kwargs)
    700 start = preferred_clock()
    702 # Send the request
--> 703 r = adapter.send(request, **kwargs)
    705 # Total elapsed time of the request (approximately)
    706 elapsed = preferred_clock() - start

File /opt/micromamba/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:95, in UniqueRequestIdAdapter.send(self, request, *args, **kwargs)
     93     logger.debug(f"Send: {_curlify(request)}")
     94 try:
---> 95     return super().send(request, *args, **kwargs)
     96 except requests.RequestException as e:
     97     request_id = request.headers.get(X_AMZN_TRACE_ID)

File /opt/micromamba/lib/python3.10/site-packages/requests/adapters.py:644, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies)
    641     timeout = TimeoutSauce(connect=timeout, read=timeout)
    643 try:
--> 644     resp = conn.urlopen(
    645         method=request.method,
    646         url=url,
    647         body=request.body,
    648         headers=request.headers,
    649         redirect=False,
    650         assert_same_host=False,
    651         preload_content=False,
    652         decode_content=False,
    653         retries=self.max_retries,
    654         timeout=timeout,
    655         chunked=chunked,
    656     )
    658 except (ProtocolError, OSError) as err:
    659     raise ConnectionError(err, request=request)

File /opt/micromamba/lib/python3.10/site-packages/urllib3/connectionpool.py:716, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)
    713     self._prepare_proxy(conn)
    715 # Make the request on the httplib connection object.
--> 716 httplib_response = self._make_request(
    717     conn,
    718     method,
    719     url,
    720     timeout=timeout_obj,
    721     body=body,
    722     headers=headers,
    723     chunked=chunked,
    724 )
    726 # If we're going to release the connection in ``finally:``, then
    727 # the response doesn't need to know about the connection. Otherwise
    728 # it will also try to release it and we'll have a double-release
    729 # mess.
    730 response_conn = conn if not release_conn else None

File /opt/micromamba/lib/python3.10/site-packages/urllib3/connectionpool.py:404, in HTTPConnectionPool._make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)
    402 # Trigger any extra validation we need to do.
    403 try:
--> 404     self._validate_conn(conn)
    405 except (SocketTimeout, BaseSSLError) as e:
    406     # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.
    407     self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)

File /opt/micromamba/lib/python3.10/site-packages/urllib3/connectionpool.py:1061, in HTTPSConnectionPool._validate_conn(self, conn)
   1059 # Force connect early to allow us to validate the connection.
   1060 if not getattr(conn, "sock", None):  # AppEngine might not have  `.sock`
-> 1061     conn.connect()
   1063 if not conn.is_verified:
   1064     warnings.warn(
   1065         (
   1066             "Unverified HTTPS request is being made to host '%s'. "
   (...)
   1071         InsecureRequestWarning,
   1072     )

File /opt/micromamba/lib/python3.10/site-packages/urllib3/connection.py:363, in HTTPSConnection.connect(self)
    361 def connect(self):
    362     # Add certificate verification
--> 363     self.sock = conn = self._new_conn()
    364     hostname = self.host
    365     tls_in_tls = False

File /opt/micromamba/lib/python3.10/site-packages/urllib3/connection.py:174, in HTTPConnection._new_conn(self)
    171     extra_kw["socket_options"] = self.socket_options
    173 try:
--> 174     conn = connection.create_connection(
    175         (self._dns_host, self.port), self.timeout, **extra_kw
    176     )
    178 except SocketTimeout:
    179     raise ConnectTimeoutError(
    180         self,
    181         "Connection to %s timed out. (connect timeout=%s)"
    182         % (self.host, self.timeout),
    183     )

File /opt/micromamba/lib/python3.10/site-packages/urllib3/util/connection.py:85, in create_connection(address, timeout, source_address, socket_options)
     83     if source_address:
     84         sock.bind(source_address)
---> 85     sock.connect(sa)
     86     return sock
     88 except socket.error as e:

KeyboardInterrupt: 
```

I have built a custom docker image for the notebook that has all the required packages

docker file for this custom image is attached

I need to pre-download all the deepseek-OCR files and requirements and add it to the custom image 

the code needs to be updated to use the downloaded weights, files, etc and not to try to download again

1.update the docker file to do that
2.update the python code to use the offline files 
